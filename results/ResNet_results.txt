Epoch 1/30
54/54 [==============================] - 912s 17s/step - loss: 0.8611 - accuracy: 0.6863 - val_loss: 1327464.3750 - val_accuracy: 0.3357
Epoch 2/30
54/54 [==============================] - 907s 17s/step - loss: 0.5935 - accuracy: 0.7748 - val_loss: 1535.7986 - val_accuracy: 0.3955
Epoch 3/30
54/54 [==============================] - 907s 17s/step - loss: 0.7423 - accuracy: 0.7688 - val_loss: 45170.9336 - val_accuracy: 0.3357
Epoch 4/30
54/54 [==============================] - 907s 17s/step - loss: 0.6250 - accuracy: 0.7610 - val_loss: 758.8051 - val_accuracy: 0.4178
Epoch 5/30
54/54 [==============================] - 907s 17s/step - loss: 0.4467 - accuracy: 0.8158 - val_loss: 17.2384 - val_accuracy: 0.6960
Epoch 6/30
54/54 [==============================] - 907s 17s/step - loss: 0.3554 - accuracy: 0.8629 - val_loss: 1.1158 - val_accuracy: 0.7465
Epoch 7/30
54/54 [==============================] - 908s 17s/step - loss: 0.3198 - accuracy: 0.8902 - val_loss: 1.4636 - val_accuracy: 0.5728
Epoch 8/30
54/54 [==============================] - 909s 17s/step - loss: 0.3617 - accuracy: 0.8676 - val_loss: 11.6565 - val_accuracy: 0.6444
Epoch 9/30
54/54 [==============================] - 908s 17s/step - loss: 0.2156 - accuracy: 0.9257 - val_loss: 0.7292 - val_accuracy: 0.7641
Epoch 10/30
54/54 [==============================] - 908s 17s/step - loss: 0.1000 - accuracy: 0.9656 - val_loss: 0.9299 - val_accuracy: 0.7054
Epoch 11/30
54/54 [==============================] - 908s 17s/step - loss: 0.0731 - accuracy: 0.9745 - val_loss: 0.5977 - val_accuracy: 0.8063
Epoch 12/30
54/54 [==============================] - 908s 17s/step - loss: 0.0596 - accuracy: 0.9780 - val_loss: 0.6068 - val_accuracy: 0.7993
Epoch 13/30
54/54 [==============================] - 908s 17s/step - loss: 0.0860 - accuracy: 0.9725 - val_loss: 1.0159 - val_accuracy: 0.7653
Epoch 14/30
54/54 [==============================] - 908s 17s/step - loss: 0.0700 - accuracy: 0.9768 - val_loss: 0.7468 - val_accuracy: 0.7899
Epoch 15/30
54/54 [==============================] - 912s 17s/step - loss: 0.0476 - accuracy: 0.9910 - val_loss: 0.7080 - val_accuracy: 0.8005
Epoch 16/30
54/54 [==============================] - 907s 17s/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.7093 - val_accuracy: 0.8052
Epoch 17/30
54/54 [==============================] - 908s 17s/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.7632 - val_accuracy: 0.8181
Epoch 18/30
54/54 [==============================] - 907s 17s/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.7543 - val_accuracy: 0.8169
Epoch 19/30
54/54 [==============================] - 909s 17s/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.7728 - val_accuracy: 0.8216
Epoch 20/30
54/54 [==============================] - 909s 17s/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.7877 - val_accuracy: 0.8181
Epoch 21/30
54/54 [==============================] - 909s 17s/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.7948 - val_accuracy: 0.8181
Epoch 22/30
54/54 [==============================] - 908s 17s/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.7976 - val_accuracy: 0.8099
Epoch 23/30
54/54 [==============================] - 908s 17s/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.8029 - val_accuracy: 0.8146
Epoch 24/30
54/54 [==============================] - 909s 17s/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.8066 - val_accuracy: 0.8146
Epoch 25/30
54/54 [==============================] - 909s 17s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.8122
Epoch 26/30
54/54 [==============================] - 907s 17s/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.8160 - val_accuracy: 0.8134
Epoch 27/30
54/54 [==============================] - 908s 17s/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.8197 - val_accuracy: 0.8169
Epoch 28/30
54/54 [==============================] - 907s 17s/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.8235 - val_accuracy: 0.8146
Epoch 29/30
54/54 [==============================] - 908s 17s/step - loss: 0.0113 - accuracy: 0.9997 - val_loss: 0.8229 - val_accuracy: 0.8134
Epoch 30/30
54/54 [==============================] - 908s 17s/step - loss: 0.0068 - accuracy: 0.9996 - val_loss: 0.8240 - val_accuracy: 0.8134
27/27 [==============================] - 40s 1s/step - loss: 0.9692 - accuracy: 0.8063
Test accuracy: 0.8063380122184753
Test accuracy: 0.81
Precision: 0.81
Sensitivity (Recall): 0.81
F1-Score: 0.81
Cohen's Kappa: 0.71
Classification Report:
                      precision    recall  f1-score   support

basal cell carcinoma       0.88      0.86      0.87       267
            melanoma       0.77      0.79      0.78       293
               nevus       0.77      0.77      0.77       292

            accuracy                           0.81       852
           macro avg       0.81      0.81      0.81       852
        weighted avg       0.81      0.81      0.81       852

Confusion Matrix:
[[230  19  18]
 [ 13 232  48]
 [ 17  50 225]]

____________________________________________

# Import necessary libraries
import os
import cv2
import pandas as pd
import numpy as np
import gc
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, cohen_kappa_score
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.applications.resnet import preprocess_input
from sklearn.utils.multiclass import unique_labels

# Load file
filepath = 'E:/TFM/code/reduced_metadata.csv'
metadata = pd.read_csv(filepath)

# Delete non-informative columns
col_drop = ['attribution', 'copyright_license', 'diagnosis_confirm_type', 'image_type', 'lesion_id']
data = metadata.drop(columns=col_drop)

# Define a list to store image information
image_info = []

# Image directory
image_directory = 'E:/TFM/BCN20000/Imagenes_256_reduced'

# Iterate through the metadata and gather image information
for index, row in metadata.iterrows():
    image_filename = row['isic_id'] + '.jpg'
    image_path = os.path.join(image_directory, image_filename)
    label = row['diagnosis']

    image = cv2.imread(image_path)
    # image = cv2.resize(image, (256, 256))  # You can resize to a smaller size for faster processing
    image = preprocess_input(image)  # Preprocess images for ResNet
    image_info.append((image, label))

# Extract images and labels from image_info
images = [item[0] for item in image_info]
labels = [item[1] for item in image_info]

# Unique number of diagnosis
num_classes = len(Counter(labels))

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(labels)

# Convert image data to NumPy arrays
images = np.array(images)

y_one_hot = to_categorical(y_encoded, num_classes=num_classes)

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(images, y_one_hot, test_size=0.2, random_state=420)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=420)

# Clean up memory
del images
del image_info
del metadata
gc.collect()

# Create the base model
base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(256, 256, 3)))

for layer in base_model.layers:
    if 'conv4_block' in layer.name:
        break
    layer.trainable = False

# Add custom layers on top of the pre-trained model
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = BatchNormalization()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.25)(x)
predictions = Dense(num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Define the number of epochs and batch size
num_epochs = 30
batch_size = 128

# Define a learning rate scheduler
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)

# When fitting the model, include the callbacks
history = model.fit(
    X_train,
    y_train,
    validation_data=(X_val, y_val),
    epochs=num_epochs,
    batch_size=batch_size,
    callbacks=[lr_scheduler]
)

plt.figure()
plt.ylabel("Loss (training and validation)")
plt.xlabel("Training Steps")
plt.ylim([0, 2])
plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])

plt.figure()
plt.ylabel("Accuracy (training and validation)")
plt.xlabel("Training Steps")
plt.ylim([0, 1])
plt.plot(history.history["accuracy"])
plt.plot(history.history["val_accuracy"])

# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test accuracy: {test_accuracy}')

# Assuming X_test contains your test images
y_pred = model.predict(X_test)

# Convert one-hot encoded predictions back to class labels
y_pred_labels = label_encoder.inverse_transform(np.argmax(y_pred, axis=1))
y_true_labels = label_encoder.inverse_transform(np.argmax(y_test, axis=1))

# Calculate accuracy
accuracy = accuracy_score(y_true_labels, y_pred_labels)
print(f'Test accuracy: {accuracy:.2f}')

# Calculate precision
precision = precision_score(y_true_labels, y_pred_labels, average='weighted')
print(f'Precision: {precision:.2f}')

# Calculate sensitivity (recall)
sensitivity = recall_score(y_true_labels, y_pred_labels, average='weighted')
print(f'Sensitivity (Recall): {sensitivity:.2f}')

# Calculate F1-Score
f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')
print(f'F1-Score: {f1:.2f}')

# Calculate Cohen's Kappa
kappa = cohen_kappa_score(y_true_labels, y_pred_labels)
print(f"Cohen's Kappa: {kappa:.2f}")

# Generate a classification report
report = classification_report(y_true_labels, y_pred_labels)
print("Classification Report:")
print(report)

# Calculate the confusion matrix
confusion = confusion_matrix(y_true_labels, y_pred_labels)
print("Confusion Matrix:")
print(confusion)

# Get class labels
classes = unique_labels(y_true_labels, y_pred_labels)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)
sns.heatmap(confusion, annot=True, fmt="d", cmap="Blues", xticklabels=classes, yticklabels=classes)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Save the model to a specific path
model.save('E:/TFM/Results with code/Trained_models/ResNet50_model.h5')
